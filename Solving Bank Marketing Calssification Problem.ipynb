{"cells":[{"cell_type":"markdown","source":["## Illustration of PySpark ML usage on Bank Marketing Dataset.\nThis notebook is realized by **[Baligh Mnassri]** and running on a Spark cluster using Python programming language on [databricks cloud community edition]. \n[Baligh Mnassri]: https://github.com/mnassrib\n[databricks cloud community edition]: https://databricks.com/try-databricks\nProblem statement and dataset can be found here: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n\nThe data are provided to test more computationally demanding machine learning algorithms. The classification goal is to predict if the customer will subscribe (yes or no) a term deposit (variable: deposit).\n\nThese data are related with direct marketing campaigns (phone calls) of a Portuguese banking institution.\n\n###### I am importing the dataset from [Kaggle]. Next, I directly upload it to [databricks cloud]. \n\n[Kaggle]: https://www.kaggle.com/rouseguy/bankbalanced/data\n\n[databricks cloud]: https://docs.databricks.com/user-guide/importing-data.html#import-data\n\n#### Attribute Information:\n##### Input variables:\n* bank client data:\n  * 1 - age (numeric)\n  * 2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n  * 3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n  * 4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n  * 5 - default: has credit in default? (categorical: 'no','yes','unknown')\n  * 6 - balance: balance level\n  * 7 - housing: has housing loan? (categorical: 'no','yes','unknown')\n  * 8 - loan: has personal loan? (categorical: 'no','yes','unknown')\n* related with the last contact of the current campaign:\n  * 9 - contact: contact communication type (categorical: 'cellular','telephone') \n  * 10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n  * 11 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n  * 12 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n* other attributes:\n  * 13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n  * 14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n  * 15 - previous: number of contacts performed before this campaign and for this client (numeric)\n  * 16 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n\n##### Output variable:\n* desired target:\n  * 17 - deposit - has the client subscribed a term deposit? (binary: 'yes', 'no')"],"metadata":{}},{"cell_type":"markdown","source":["### Importing needful libraries"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import mean, col, split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler, VectorIndexer\nfrom pyspark.ml.feature import QuantileDiscretizer, OneHotEncoderEstimator, OneHotEncoder\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nfrom pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["#### Beginning with SparkSession\n\n***The entry point into all functionality in Spark is the SparkSession class.\nTo create a basic SparkSession, just use SparkSession.builder***"],"metadata":{}},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"Spark ML applied on Bank Marketing dataset\").getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["Read the data by given the dataset path after uploaded it to [databricks cloud].\n[databricks cloud]: https://docs.databricks.com/user-guide/importing-data.html#import-data"],"metadata":{}},{"cell_type":"code","source":["bank_data_path = \"/FileStore/tables/bank.csv\"\n\nbank_df = spark.read.csv(bank_data_path, header = 'True', inferSchema = 'True')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["bank_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- age: integer (nullable = true)\n-- job: string (nullable = true)\n-- marital: string (nullable = true)\n-- education: string (nullable = true)\n-- default: string (nullable = true)\n-- balance: integer (nullable = true)\n-- housing: string (nullable = true)\n-- loan: string (nullable = true)\n-- contact: string (nullable = true)\n-- day: integer (nullable = true)\n-- month: string (nullable = true)\n-- duration: integer (nullable = true)\n-- campaign: integer (nullable = true)\n-- pdays: integer (nullable = true)\n-- previous: integer (nullable = true)\n-- poutcome: string (nullable = true)\n-- deposit: string (nullable = true)\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["bank_df.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\nage|       job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n 59|    admin.|married|secondary|     no|   2343|    yes|  no|unknown|  5|  may|    1042|       1|   -1|       0| unknown|    yes|\n 56|    admin.|married|secondary|     no|     45|     no|  no|unknown|  5|  may|    1467|       1|   -1|       0| unknown|    yes|\n 41|technician|married|secondary|     no|   1270|    yes|  no|unknown|  5|  may|    1389|       1|   -1|       0| unknown|    yes|\n 55|  services|married|secondary|     no|   2476|    yes|  no|unknown|  5|  may|     579|       1|   -1|       0| unknown|    yes|\n 54|    admin.|married| tertiary|     no|    184|     no|  no|unknown|  5|  may|     673|       2|   -1|       0| unknown|    yes|\n+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Number of cutomers in the dataframe"],"metadata":{}},{"cell_type":"code","source":["clients_count = bank_df.count()\nprint(\"Number of cutomers is {}\".format(clients_count))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of cutomers is 11162\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Number of customers which are subscribed vs. those not subscribed a term deposit"],"metadata":{}},{"cell_type":"code","source":["groupBy_clients = bank_df.groupBy(\"deposit\").count()\n\ngroupBy_clients.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----+\ndeposit|count|\n+-------+-----+\n     no| 5873|\n    yes| 5289|\n+-------+-----+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["display(groupBy_clients)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>deposit</th><th>count</th></tr></thead><tbody><tr><td>no</td><td>5873</td></tr><tr><td>yes</td><td>5289</td></tr></tbody></table></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Summary statistics for the numeric variables"],"metadata":{}},{"cell_type":"code","source":["bank_df.describe([t[0] for t in bank_df.dtypes if t[1] == 'int']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\nsummary|               age|           balance|               day|          duration|          campaign|             pdays|          previous|\n+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n  count|             11162|             11162|             11162|             11162|             11162|             11162|             11162|\n   mean|41.231947679627304|1528.5385235620856|15.658036194230425|371.99381831213043| 2.508421429851281| 51.33040673714388|0.8325568894463358|\n stddev|11.913369192215518| 3225.413325946149| 8.420739541006462|347.12838571630687|2.7220771816614824|108.75828197197717| 2.292007218670508|\n    min|                18|             -6847|                 1|                 2|                 1|                -1|                 0|\n    max|                95|             81204|                31|              3881|                63|               854|                58|\n+-------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["display(bank_df.groupBy(\"job\").count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>job</th><th>count</th></tr></thead><tbody><tr><td>management</td><td>2566</td></tr><tr><td>retired</td><td>778</td></tr><tr><td>unknown</td><td>70</td></tr><tr><td>self-employed</td><td>405</td></tr><tr><td>student</td><td>360</td></tr><tr><td>blue-collar</td><td>1944</td></tr><tr><td>entrepreneur</td><td>328</td></tr><tr><td>admin.</td><td>1334</td></tr><tr><td>technician</td><td>1823</td></tr><tr><td>services</td><td>923</td></tr><tr><td>housemaid</td><td>274</td></tr><tr><td>unemployed</td><td>357</td></tr></tbody></table></div>"]}}],"execution_count":17},{"cell_type":"code","source":["display(bank_df.groupBy(\"housing\", \"deposit\").count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>housing</th><th>deposit</th><th>count</th></tr></thead><tbody><tr><td>no</td><td>no</td><td>2527</td></tr><tr><td>no</td><td>yes</td><td>3354</td></tr><tr><td>yes</td><td>yes</td><td>1935</td></tr><tr><td>yes</td><td>no</td><td>3346</td></tr></tbody></table></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["### Data preprocessing"],"metadata":{}},{"cell_type":"markdown","source":["The following function code initially inspired from [here] indexes each categorical column using the StringIndexer, and then converts the indexed categories into one-hot encoded variables. The resulting output has the binary vectors appended to the end of each row. Then, the StringIndexer is used again to encode the labels to label indices. Finally, the VectorAssembler function is used to combine all the feature columns into a single vector column. This includes both the numeric columns and the one-hot encoded binary vector columns in the dataset. Index labels, adding metadata to the label column by using the StringIndexer again to encode the labels to label indices.\n\nRunning the stages as a Pipeline is used to chain multiple Transformers and Estimators together. This puts the data through all of the feature transformations we described in a single call.\n[here]: https://runawayhorse001.github.io/LearningApacheSpark/classification.html"],"metadata":{}},{"cell_type":"code","source":["def get_dummy(df, categoricalCols, continuousCols, labelCol):\n  \n  indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categoricalCols]\n\n  encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(),\n                             outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n              for indexer in indexers]\n\n  assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n                              + continuousCols, outputCol=\"features\")\n  \n  indexer = StringIndexer(inputCol=labelCol, outputCol='indexedLabel')\n\n  pipeline = Pipeline(stages = indexers + encoders + [assembler] + [indexer])\n\n  model=pipeline.fit(df)\n  data = model.transform(df)\n\n  data = data.withColumn('label', col(labelCol))\n  \n  return data.select('features', 'indexedLabel', 'label'), StringIndexer(inputCol='label').fit(data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["Once, we have defined our lists of categorical as well as numerical variables, we can transform the data:"],"metadata":{}},{"cell_type":"code","source":["categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\nnumericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n(bank_df, labelindexer) = get_dummy(bank_df, categoricalColumns, numericCols, 'deposit')\nbank_df.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------+-----+\n            features|indexedLabel|label|\n+--------------------+------------+-----+\n(30,[3,11,13,16,1...|         1.0|  yes|\n(30,[3,11,13,16,1...|         1.0|  yes|\n(30,[2,11,13,16,1...|         1.0|  yes|\n(30,[4,11,13,16,1...|         1.0|  yes|\n(30,[3,11,14,16,1...|         1.0|  yes|\n+--------------------+------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["**It is essential to fit the following ``featureIndexer`` model on the whole of the ``bank_df`` dataframe**. *Automatically identify categorical features, and index them. Set maxCategories so features with > 4 distinct values are treated as continuous.*"],"metadata":{}},{"cell_type":"code","source":["featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(bank_df)\n\nfeatureIndexer.transform(bank_df).show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------+-----+--------------------+\n            features|indexedLabel|label|     indexedFeatures|\n+--------------------+------------+-----+--------------------+\n(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n(30,[3,11,13,16,1...|         1.0|  yes|(30,[3,11,13,16,1...|\n(30,[2,11,13,16,1...|         1.0|  yes|(30,[2,11,13,16,1...|\n(30,[4,11,13,16,1...|         1.0|  yes|(30,[4,11,13,16,1...|\n(30,[3,11,14,16,1...|         1.0|  yes|(30,[3,11,14,16,1...|\n+--------------------+------------+-----+--------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["bank_df.show(5, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------------------------------------------------------------+------------+-----+\nfeatures                                                                                                |indexedLabel|label|\n+--------------------------------------------------------------------------------------------------------+------------+-----+\n(30,[3,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,59.0,2343.0,1042.0,1.0,-1.0])     |1.0         |yes  |\n(30,[3,11,13,16,17,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,56.0,45.0,1467.0,1.0,-1.0])|1.0         |yes  |\n(30,[2,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,41.0,1270.0,1389.0,1.0,-1.0])     |1.0         |yes  |\n(30,[4,11,13,16,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,55.0,2476.0,579.0,1.0,-1.0])      |1.0         |yes  |\n(30,[3,11,14,16,17,18,20,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,54.0,184.0,673.0,2.0,-1.0])|1.0         |yes  |\n+--------------------------------------------------------------------------------------------------------+------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["### Data splitting\n\nNow that the dataset is all set, let's randomly split it into training and test sets. Set seed for reproducibility."],"metadata":{}},{"cell_type":"code","source":["(trainingData, testData) = bank_df.randomSplit([0.8, 0.2], seed=10)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 8944\nTest Dataset Count: 2218\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["print(\"The first 5 samples of the Training Dataset:\")\ntrainingData.show(5, False)\nprint(\"The first 5 samples of the Test Dataset:\")\ntestData.show(5, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The first 5 samples of the Training Dataset:\n+---------------------------------------------------------------------------------------------------------+------------+-----+\nfeatures                                                                                                 |indexedLabel|label|\n+---------------------------------------------------------------------------------------------------------+------------+-----+\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,27.0,2071.0,449.0,1.0,-1.0])|1.0         |yes  |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,30.0,850.0,507.0,2.0,-1.0]) |1.0         |yes  |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,33.0,336.0,179.0,3.0,-1.0]) |1.0         |yes  |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,33.0,369.0,446.0,1.0,-1.0]) |1.0         |yes  |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,34.0,355.0,314.0,3.0,-1.0]) |0.0         |no   |\n+---------------------------------------------------------------------------------------------------------+------------+-----+\nonly showing top 5 rows\n\nThe first 5 samples of the Test Dataset:\n+---------------------------------------------------------------------------------------------------------+------------+-----+\nfeatures                                                                                                 |indexedLabel|label|\n+---------------------------------------------------------------------------------------------------------+------------+-----+\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,33.0,333.0,80.0,6.0,-1.0])  |0.0         |no   |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.0,80.0,155.0,3.0,-1.0])  |0.0         |no   |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,57.0,123.0,154.0,2.0,-1.0]) |0.0         |no   |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,57.0,7162.0,83.0,1.0,-1.0]) |0.0         |no   |\n(30,[0,11,13,16,17,18,19,21,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,59.0,4412.0,162.0,2.0,-1.0])|1.0         |yes  |\n+---------------------------------------------------------------------------------------------------------+------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["#### Fit and evaluate models\n\nWe are now ready to try out some of the Binary Classification algorithms available in the Pipelines API.\n\nOut of these algorithms, the below are also capable of supporting multiclass classification with the Python API:\n- Decision Tree Classifier\n- Random Forest Classifier\n\nThese are the general steps we will take to build our models:\n- Create initial model using the training set\n- Tune parameters with a `ParamGrid` and 5-fold Cross Validation\n- Evaluate the best model obtained from the Cross Validation using the test set\n\nWe use the `BinaryClassificationEvaluator` to evaluate our models, which uses [areaUnderROC] as the default metric.\n\n[areaUnderROC]: https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve"],"metadata":{}},{"cell_type":"markdown","source":["### Logistic Regression\n\nFor more details about [Logistic Regression], read the [classification and regression] section of MLlib Programming Guide.\nIn the Pipelines API, It is now able to perform Elastic-Net Regularization with Logistic Regression, as well as other linear methods.\n\n[classification and regression]: https://spark.apache.org/docs/latest/ml-classification-regression.html\n[Logistic Regression]: https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\n\nCreate initial LogisticRegression model and then train it with the Training Data"],"metadata":{}},{"cell_type":"code","source":["#lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\") # if you would using indexedFeatures instead features column\nlr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["Pipeline architecture:\n  * Convert indexed labels back to original labels\n  * Chain indexers and tree in a Pipeline\n  * Train model"],"metadata":{}},{"cell_type":"code","source":["labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelindexer.labels) \n\npipeline = Pipeline(stages=[featureIndexer, lr, labelConverter])\n\nlrModel = pipeline.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"markdown","source":["Make predictions on the test data using the ``transform()`` method. ``LogisticRegression.transform()`` will only use the column given in featuresCol parameter."],"metadata":{}},{"cell_type":"code","source":["predictions = lrModel.transform(testData)\n\npredictions.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n            features|indexedLabel|label|     indexedFeatures|       rawPrediction|         probability|prediction|predictedLabel|\n+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\n(30,[0,11,13,16,1...|         0.0|   no|(30,[0,11,13,16,1...|[1.89371369272437...|[0.86917838386403...|       0.0|            no|\n(30,[0,11,13,16,1...|         0.0|   no|(30,[0,11,13,16,1...|[1.12785346095205...|[0.75544254540451...|       0.0|            no|\n(30,[0,11,13,16,1...|         0.0|   no|(30,[0,11,13,16,1...|[1.00924474870032...|[0.73287231933414...|       0.0|            no|\n(30,[0,11,13,16,1...|         0.0|   no|(30,[0,11,13,16,1...|[1.04490392640843...|[0.73979511309234...|       0.0|            no|\n(30,[0,11,13,16,1...|         1.0|  yes|(30,[0,11,13,16,1...|[0.83428161071270...|[0.69725949203309...|       0.0|            no|\n+--------------------+------------+-----+--------------------+--------------------+--------------------+----------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["You can print the elements in predictions, view model's predictions and probabilities of each prediction class. You can select any columns in the above schema to view as well. You are generally interested by the label, prediction and the probability:"],"metadata":{}},{"cell_type":"code","source":["predictions.select(\"features\", \"label\", \"probability\", \"predictedLabel\").show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+--------------------+--------------+\n            features|label|         probability|predictedLabel|\n+--------------------+-----+--------------------+--------------+\n(30,[0,11,13,16,1...|   no|[0.86917838386403...|            no|\n(30,[0,11,13,16,1...|   no|[0.75544254540451...|            no|\n(30,[0,11,13,16,1...|   no|[0.73287231933414...|            no|\n(30,[0,11,13,16,1...|   no|[0.73979511309234...|            no|\n(30,[0,11,13,16,1...|  yes|[0.69725949203309...|            no|\n+--------------------+-----+--------------------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["**Compute the model accuracy**\n\nYou can create a DataFrame with the label and the prediction to check the number of class in the label and the prediction:"],"metadata":{}},{"cell_type":"code","source":["cm = predictions.select(\"label\", \"predictedLabel\")\t\t\t\ncm.groupby('label').agg({'label': 'count'}).show()\t\ncm.groupby('predictedLabel').agg({'predictedLabel': 'count'}).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+\nlabel|count(label)|\n+-----+------------+\n   no|        1197|\n  yes|        1021|\n+-----+------------+\n\n+--------------+---------------------+\npredictedLabel|count(predictedLabel)|\n+--------------+---------------------+\n            no|                 1246|\n           yes|                  972|\n+--------------+---------------------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["predictions.groupBy('label', 'predictedLabel').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------+-----+\nlabel|predictedLabel|count|\n+-----+--------------+-----+\n   no|            no| 1001|\n   no|           yes|  196|\n  yes|           yes|  776|\n  yes|            no|  245|\n+-----+--------------+-----+\n\n</div>"]}}],"execution_count":41},{"cell_type":"markdown","source":["For instance, in the test dataset, there are 1021 customers that have the intension to subscribe a deposit and 1197 no. The classifier, however, predicted 972 clients having the intension to subscribe a deposit. You can compute the accuracy by computing the count when the labels are correctly classified over the total number of rows."],"metadata":{}},{"cell_type":"code","source":["print(\"The Accuracy for test set is {}\".format(cm.filter(cm.label == cm.predictedLabel).count()/cm.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.8011722272317403\n</div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["Indeed, the accuracy of the model and other metrics can be computed using the ``MulticlassClassificationEvaluator()`` function:"],"metadata":{}},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nprint(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.8011722272317403\n</div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["**Use of RDD principles to compute some other metrics**\n\nWe can also generate a Confusion Matrix to better see the results of the predictions. ``ConfusionMatrix()`` works only with RDDs, so we will have to convert our DataFrame of (prediction, label) into a RDD.\n\n``confusionMatrix()`` returns a DenseMatrix with the columns representing the predicted class ordered by ascending class label, and each row represents the actual class ordered by ascending class label. The diagonal from top left to bottom right represents the observations that were predicted correctly."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.evaluation import BinaryClassificationMetrics\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\npredictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n\n# Instantiate metrics object \nmetricsMulti = MulticlassMetrics(predictionAndLabel)\nmetricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n# Overall statistics \nconfusionMatrix = metricsMulti.confusionMatrix()\nprecision = metricsMulti.precision(label=1) \nrecall = metricsMulti.recall(label=1) \nf1Score = metricsMulti.fMeasure() \nprint(\"Summary Stats\")\nprint(\"Confusion Matrix = \\n %s\" % confusionMatrix)\nprint(\"Precision = %s\" % precision) \nprint(\"Recall = %s\" % recall) \nprint(\"F1 Score = %s\" % f1Score) \n\n# Area under precision-recall curve \nprint(\"Area under PR = %s\" % metricsBinary.areaUnderPR) \n# Area under ROC curve \nprint(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Summary Stats\nConfusion Matrix = \n DenseMatrix([[ 1001.,   196.],\n             [  245.,   776.]])\nPrecision = 0.7983539094650206\nRecall = 0.7600391772771793\nF1 Score = 0.8011722272317403\nArea under PR = 0.7577970158754894\nArea under ROC = 0.7981482436093499\n</div>"]}}],"execution_count":47},{"cell_type":"markdown","source":["**Compute the area under ROC metric**"],"metadata":{}},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\nprint(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The area under ROC for test set is 0.7981482436093499\n</div>"]}}],"execution_count":49},{"cell_type":"markdown","source":["Now, we will try tuning the model with the ``ParamGridBuilder`` and the ``CrossValidator``. If you are unsure what params are available for tuning, you can use ``explainParams()`` to print a list of all params and their definitions."],"metadata":{}},{"cell_type":"code","source":["print(lr.explainParams())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">aggregationDepth: suggested depth for treeAggregate (&gt;= 2). (default: 2)\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\nfamily: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\nfeaturesCol: features column name. (default: features, current: features)\nfitIntercept: whether to fit an intercept term. (default: True)\nlabelCol: label column name. (default: label, current: indexedLabel)\nlowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\nlowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\nmaxIter: max number of iterations (&gt;= 0). (default: 100)\npredictionCol: prediction column name. (default: prediction)\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\nrawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\nregParam: regularization parameter (&gt;= 0). (default: 0.0)\nstandardization: whether to standardize the training features before fitting the model. (default: True)\nthreshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values &gt; 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class&apos;s threshold. (undefined)\ntol: the convergence tolerance for iterative algorithms (&gt;= 0). (default: 1e-06)\nupperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\nupperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["**Hyperparameter tuning using 5-fold cross validation**"],"metadata":{}},{"cell_type":"markdown","source":["In the following example, we indicate 3 values for regParam, 3 values for maxIter, and 3 values for elasticNetParam,\nthis grid will have then 3 x 3 x 3 = 27 parameter settings for CrossValidator to choose from.\nWe will create a 5-fold CrossValidator.\n\n***Create ParamGrid for Cross Validation***"],"metadata":{}},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"markdown","source":["***Create and run 5-fold CrossValidator***"],"metadata":{}},{"cell_type":"code","source":["#cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n#pipeline = Pipeline(stages=[featureIndexer, cv, labelConverter])\n#cvModel = pipeline.fit(trainingData)\n\npipeline = Pipeline(stages=[featureIndexer, lr, labelConverter]) \ncv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5, parallelism=10, seed=100)\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"markdown","source":["cvModel uses the best model found from the Cross Validation. Use test or new data to measure the accuracy of the model."],"metadata":{}},{"cell_type":"code","source":["predictions = cvModel.transform(testData)\n\npredictions.select(\"features\", \"label\", \"probability\", \"predictedLabel\").show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----+--------------------+--------------+\n            features|label|         probability|predictedLabel|\n+--------------------+-----+--------------------+--------------+\n(30,[0,11,13,16,1...|   no|[0.84080130499565...|            no|\n(30,[0,11,13,16,1...|   no|[0.73331025269839...|            no|\n(30,[0,11,13,16,1...|   no|[0.73767741618965...|            no|\n(30,[0,11,13,16,1...|   no|[0.73046014362709...|            no|\n(30,[0,11,13,16,1...|  yes|[0.70437123017669...|            no|\n+--------------------+-----+--------------------+--------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":58},{"cell_type":"markdown","source":["***Evaluate the best model***"],"metadata":{}},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nprint(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.7908025247971145\n</div>"]}}],"execution_count":60},{"cell_type":"code","source":["predictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n\n# Instantiate metrics object \nmetricsMulti = MulticlassMetrics(predictionAndLabel)\nmetricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n# Overall statistics \nconfusionMatrix = metricsMulti.confusionMatrix()\nprecision = metricsMulti.precision(label=1) \nrecall = metricsMulti.recall(label=1) \nf1Score = metricsMulti.fMeasure() \nprint(\"Summary Stats\")\nprint(\"Confusion Matrix = \\n %s\" % confusionMatrix)\nprint(\"Precision = %s\" % precision) \nprint(\"Recall = %s\" % recall) \nprint(\"F1 Score = %s\" % f1Score) \n\n# Area under precision-recall curve \nprint(\"Area under PR = %s\" % metricsBinary.areaUnderPR) \n# Area under ROC curve \nprint(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Summary Stats\nConfusion Matrix = \n DenseMatrix([[ 992.,  205.],\n             [ 259.,  762.]])\nPrecision = 0.7880041365046536\nRecall = 0.7463271302644466\nF1 Score = 0.7908025247971145\nArea under PR = 0.7464424344425616\nArea under ROC = 0.787532821606743\n</div>"]}}],"execution_count":61},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\nprint(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The area under ROC for test set is 0.787532821606743\n</div>"]}}],"execution_count":62},{"cell_type":"markdown","source":["### Decision Trees\n\nYou can read more about [Decision Trees](http://spark.apache.org/docs/latest/mllib-decision-tree.html) in the Spark MLLib Programming Guide. Decision trees are a popular family of classification and regression methods."],"metadata":{}},{"cell_type":"code","source":["# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\")\n\n# Train model with Training Data.\ndtModel = dt.fit(trainingData)\n\n# Make predictions on test data.\npredictions = dtModel.transform(testData)\n\n# Evaluate the model by computing the metrics. \nevaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nprint(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))\n\nprint(\"===============================================\")\n\npredictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n\n# Instantiate metrics object \nmetricsMulti = MulticlassMetrics(predictionAndLabel)\nmetricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n# Overall statistics \nconfusionMatrix = metricsMulti.confusionMatrix()\nprecision = metricsMulti.precision(label=1) \nrecall = metricsMulti.recall(label=1) \nf1Score = metricsMulti.fMeasure() \nprint(\"Summary Stats\")\nprint(\"Confusion Matrix = \\n %s\" % confusionMatrix)\nprint(\"Precision = %s\" % precision) \nprint(\"Recall = %s\" % recall) \nprint(\"F1 Score = %s\" % f1Score) \n\n# Area under precision-recall curve \nprint(\"Area under PR = %s\" % metricsBinary.areaUnderPR) \n# Area under ROC curve \nprint(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)\n\nprint(\"===============================================\")\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\nprint(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predictions)))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.8002705139765555\n===============================================\nSummary Stats\nConfusion Matrix = \n DenseMatrix([[ 960.,  237.],\n             [ 206.,  815.]])\nPrecision = 0.7747148288973384\nRecall = 0.7982370225269344\nF1 Score = 0.8002705139765555\nArea under PR = 0.7429986762539265\nArea under ROC = 0.8001210175291313\n===============================================\nThe area under ROC for test set is 0.8001210175291313\n</div>"]}}],"execution_count":64},{"cell_type":"markdown","source":["**Hyperparameter tuning using 5-fold cross validation**"],"metadata":{}},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1, 2, 6, 10])\n             .addGrid(dt.maxBins, [20, 40, 80])\n             .build())\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\n\npipeline = Pipeline(stages=[featureIndexer, dt, labelConverter]) \ncv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5, parallelism=10, seed=100)\ncvModel = cv.fit(trainingData)\n\npredictions = cvModel.transform(testData)\n\n# Evaluate the best model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nprint(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))\n\nprint(\"===============================================\")\n\npredictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n\n# Instantiate metrics object \nmetricsMulti = MulticlassMetrics(predictionAndLabel)\nmetricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n# Overall statistics \nconfusionMatrix = metricsMulti.confusionMatrix()\nprecision = metricsMulti.precision(label=1) \nrecall = metricsMulti.recall(label=1) \nf1Score = metricsMulti.fMeasure() \nprint(\"Summary Stats\")\nprint(\"Confusion Matrix = \\n %s\" % confusionMatrix)\nprint(\"Precision = %s\" % precision) \nprint(\"Recall = %s\" % recall) \nprint(\"F1 Score = %s\" % f1Score) \n\n# Area under precision-recall curve \nprint(\"Area under PR = %s\" % metricsBinary.areaUnderPR) \n# Area under ROC curve \nprint(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)\n\nprint(\"===============================================\")\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\nprint(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.8056807935076645\n===============================================\nSummary Stats\nConfusion Matrix = \n DenseMatrix([[ 933.,  264.],\n             [ 167.,  854.]])\nPrecision = 0.7638640429338104\nRecall = 0.8364348677766895\nF1 Score = 0.8056807935076645\nArea under PR = 0.7390398097462273\nArea under ROC = 0.8079417446652872\n===============================================\nThe area under ROC for test set is 0.8079417446652872\n</div>"]}}],"execution_count":66},{"cell_type":"markdown","source":["### Random Forest\n\nYou can read more about [Random Forest](https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#random-forest-classifier) in the Spark MLLib Programming Guide."],"metadata":{}},{"cell_type":"code","source":["# Create initial Random Forest Classifier\nrf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\")\n\n# Train model with Training Data.\nrfModel = rf.fit(trainingData)\n\n# Make predictions on test data.\npredictions = rfModel.transform(testData)\n\n# Evaluate the model by computing the metrics. \nevaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nprint(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))\n\nprint(\"===============================================\")\n\npredictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n\n# Instantiate metrics object \nmetricsMulti = MulticlassMetrics(predictionAndLabel)\nmetricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n# Overall statistics \nconfusionMatrix = metricsMulti.confusionMatrix()\nprecision = metricsMulti.precision(label=1) \nrecall = metricsMulti.recall(label=1) \nf1Score = metricsMulti.fMeasure() \nprint(\"Summary Stats\")\nprint(\"Confusion Matrix = \\n %s\" % confusionMatrix)\nprint(\"Precision = %s\" % precision) \nprint(\"Recall = %s\" % recall) \nprint(\"F1 Score = %s\" % f1Score) \n\n# Area under precision-recall curve \nprint(\"Area under PR = %s\" % metricsBinary.areaUnderPR) \n# Area under ROC curve \nprint(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)\n\nprint(\"===============================================\")\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\nprint(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.7935076645626691\n===============================================\nSummary Stats\nConfusion Matrix = \n DenseMatrix([[ 950.,  247.],\n             [ 211.,  810.]])\nPrecision = 0.7663197729422895\nRecall = 0.7933398628795298\nF1 Score = 0.7935076645626691\nArea under PR = 0.7347012724760997\nArea under ROC = 0.7934953282651619\n===============================================\nThe area under ROC for test set is 0.7934953282651619\n</div>"]}}],"execution_count":68},{"cell_type":"markdown","source":["**Hyperparameter tuning using 5-fold cross validation**"],"metadata":{}},{"cell_type":"code","source":["paramGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\n\npipeline = Pipeline(stages=[featureIndexer, rf, labelConverter]) \ncv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5, parallelism=10, seed=100)\ncvModel = cv.fit(trainingData)\n\npredictions = cvModel.transform(testData)\n\n# Evaluate the best model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\nprint(\"The Accuracy for test set is {}\".format(evaluator.evaluate(predictions)))\n\nprint(\"===============================================\")\n\npredictionAndLabel = predictions.select(\"prediction\", \"indexedLabel\").rdd\n\n# Instantiate metrics object \nmetricsMulti = MulticlassMetrics(predictionAndLabel)\nmetricsBinary= BinaryClassificationMetrics(predictionAndLabel)\n# Overall statistics \nconfusionMatrix = metricsMulti.confusionMatrix()\nprecision = metricsMulti.precision(label=1) \nrecall = metricsMulti.recall(label=1) \nf1Score = metricsMulti.fMeasure() \nprint(\"Summary Stats\")\nprint(\"Confusion Matrix = \\n %s\" % confusionMatrix)\nprint(\"Precision = %s\" % precision) \nprint(\"Recall = %s\" % recall) \nprint(\"F1 Score = %s\" % f1Score) \n\n# Area under precision-recall curve \nprint(\"Area under PR = %s\" % metricsBinary.areaUnderPR) \n# Area under ROC curve \nprint(\"Area under ROC = %s\" % metricsBinary.areaUnderROC)\n\nprint(\"===============================================\")\n\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"indexedLabel\")\nprint(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predictions)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The Accuracy for test set is 0.8070333633904418\n===============================================\nSummary Stats\nConfusion Matrix = \n DenseMatrix([[ 948.,  249.],\n             [ 179.,  842.]])\nPrecision = 0.7717690192483959\nRecall = 0.8246816846229187\nF1 Score = 0.8070333633904418\nArea under PR = 0.7444680652604925\nArea under ROC = 0.8083308172488027\n===============================================\nThe area under ROC for test set is 0.8083308172488027\n</div>"]}}],"execution_count":70},{"cell_type":"markdown","source":["## Conclusion\nThis tutorial analyses a binary classification example using Spark ML applied with Python programming language. The data provided here are related with direct marketing campaigns (phone calls) of a Portuguese banking institution. Three main algorithm classifiers are tested which are Logistic regression, Decision trees and Random forest.  Different metrics are computed after hyperparameter tunings using 5-fold cross validation to evaluate the models corresponding to these algorithms."],"metadata":{}}],"metadata":{"name":"Solving Bank Marketing Calssification Problem","notebookId":2297613386094950},"nbformat":4,"nbformat_minor":0}
